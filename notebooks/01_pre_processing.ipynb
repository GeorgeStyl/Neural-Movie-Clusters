{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Imports**\n",
   "id": "bd9fa731bdaa1abd"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-28T18:13:50.627400850Z",
     "start_time": "2026-02-28T18:13:50.600228390Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load files",
   "id": "eff5f9f06a07200d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-28T18:13:51.033273413Z",
     "start_time": "2026-02-28T18:13:50.646050164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = np.load('../data/Original_Dataset.npy', allow_pickle=True)\n",
    "# Check the math \"dimensions\"\n",
    "print(f\"Type: {type(data)}\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "\n",
    "# See the first \"row\"\n",
    "print(\"First entry:\")\n",
    "print(data[0])"
   ],
   "id": "375dcf7aee1adaf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: (4669820,)\n",
      "First entry:\n",
      "ur4592644,tt0120884,10,16 January 2005\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-28T18:13:51.081652657Z",
     "start_time": "2026-02-28T18:13:51.050308742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check total records\n",
    "total_records = data.shape[0]\n",
    "print(f\"We have {total_records:,} movie review records.\")\n",
    "\n",
    "# Since it's a 1D array of strings, we can't slice it like a matrix.\n",
    "# Let's see the first 3 full entries to see the pattern\n",
    "print(\"First 3 entries:\")\n",
    "print(data[:3])"
   ],
   "id": "16962b1419a32bdd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 4,669,820 movie review records.\n",
      "First 3 entries:\n",
      "['ur4592644,tt0120884,10,16 January 2005'\n",
      " 'ur3174947,tt0118688,3,16 January 2005'\n",
      " 'ur3780035,tt0387887,8,16 January 2005']\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convert data to DF",
   "id": "7831841369ecbc55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-28T18:14:06.229625686Z",
     "start_time": "2026-02-28T18:13:51.088244924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Load the raw strings\n",
    "raw_data = np.load('../data/Original_Dataset.npy', allow_pickle=True)\n",
    "\n",
    "# 2. Split the strings into a list of lists\n",
    "# We limit to the first 1,000,000 rows if your RAM is struggling,\n",
    "# but let's try the full set first.\n",
    "split_data = [line.split(',') for line in raw_data]\n",
    "\n",
    "# 3. Create the DataFrame\n",
    "df = pd.DataFrame(split_data, columns=['User_ID', 'Movie_ID', 'Rating', 'Date'])\n",
    "\n",
    "# 4. Fix Data Types (Crucial for Math!)\n",
    "df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "print(\"✅ Data Transformed into DataFrame\")\n",
    "print(df.head())"
   ],
   "id": "2071fd4f9826c4ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Transformed into DataFrame\n",
      "     User_ID   Movie_ID  Rating       Date\n",
      "0  ur4592644  tt0120884      10 2005-01-16\n",
      "1  ur3174947  tt0118688       3 2005-01-16\n",
      "2  ur3780035  tt0387887       8 2005-01-16\n",
      "3  ur4592628  tt0346491       1 2005-01-16\n",
      "4  ur3174947  tt0094721       8 2005-01-16\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a small csv out of DF for better visualization",
   "id": "2070760a9dd8865e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-28T18:14:14.614606065Z",
     "start_time": "2026-02-28T18:14:06.251505706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the full dataset\n",
    "df.to_csv('../data/cleaned_movies_full.csv', index=False)\n",
    "\n",
    "# Save a smaller 'preview' version (first 1000 rows) for quick viewing\n",
    "df.head(1000).to_csv('../data/preview_movies.csv', index=False)\n",
    "\n",
    "print(\"✅ CSV files created in the /data folder.\")"
   ],
   "id": "b3ef76461369f13e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV files created in the /data folder.\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
